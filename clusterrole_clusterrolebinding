View the Persistent Volume
View the Persistent Volume within the cluster:

kubectl get pv
Create a ClusterRole
Create the ClusterRole:

kubectl create clusterrole pv-reader --verb=get,list --resource=persistentvolumes
Create a ClusterRoleBinding
Create the ClusterRoleBinding:

kubectl create clusterrolebinding pv-test --clusterrole=pv-reader --serviceaccount=web:default
Create a Pod to Access the PV
Create the curlpod.yaml file:

vim curlpod.yaml
Add the following YAML to create a pod that will proxy the connection and allow you to curl the address:

apiVersion: v1
kind: Pod
metadata:
  name: curlpod
  namespace: web
spec:
  containers:
  - image: tutum/curl
    command: ["sleep", "9999999"]
    name: main
  - image: linuxacademycontent/kubectl-proxy
    name: proxy
  restartPolicy: Always
Save and exit the file by pressing Escape followed by :wq.

Create the pod:

kubectl apply -f curlpod.yaml
Request Access to the PV from the Pod
Open a new shell to the pod:

kubectl exec -it curlpod -n web -- sh
If it doesn't work immediately, wait a minute or so and then run the command again.

Curl the PV resource:

curl localhost:8001/api/v1/persistentvolumes



########################### task #################################################

Access the Kubernetes cluster within this lab environment. Within the cluster, a Persistent Volume (PV) has already been provisioned. You will need to make sure you can access the PV directly from a pod within your cluster. Create a pod with two containers in order to do so.
The first container, using the image tutum/curl, will allow you to use curl to directly access the Kubernetes REST API.
The second container, using the image linuxacademycontent/kubectl-proxy, will allow you to create a proxy between the container and the Kubernetes API Server. Ensure this pod is created in the same namespace as the PV.
By default, pods cannot access PVs directly, so you will need to create a ClusterRole and test the access after it's been created. Every ClusterRole requires a ClusterRoleBinding to bind the role to a user, service account, or group. After you have created the ClusterRole and ClusterRoleBinding, try to access the PV directly from a pod.

View the Persistent Volume
Use one command that will list the persistent volumes within the cluster.
Create a ClusterRole and ClusterRoleBinding
Use one command that will create a new ClusterRole with the verb get and list to the resource persistentvolumes.
Use one command that will create a new ClusterRoleBinding to the ClusterRole, in the web namespace and using the default service account.
Create a pod to access the PV
Create the YAML file including the two containers, using the two images tutum/curl and linuxacademycontent/kubectl-proxy.
Issue a command to the curl container to sleep for 1 hour (3600 seconds).
Apply the YAML to the Kubernetes cluster to run the pod.
Request access to the PV from the pod
Open a shell inside the container.
From the container shell prompt, issue the curl command to request persistent volumes from the API server.


######################clusterrole yaml #########################################
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  creationTimestamp: null
  name: pv-reader
rules:
- apiGroups:
  - ""
  resources:
  - persistentvolumes
  verbs:
  - get
  - list
  
######################clusterrolebinding yaml #########################################
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  creationTimestamp: null
  name: pv-reader-rb
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: pv-reader
subjects:
- kind: ServiceAccount
  name: default
  namespace: web
  
######################pod yaml #########################################

apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  namespace: web
  labels:
    app: myapp
spec:
  containers:
  - name: curl
    image: tutum/curl
    command: ['sh', '-c', 'sleep 3600']
  - name: kubectl-proxy
    image: linuxacademycontent/kubectl-proxy
 ###########################################################################   


